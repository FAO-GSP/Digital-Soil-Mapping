verbose = TRUE,
tuneGrid = tuneGrid,
keep.inbag = T)
c(i,names(covs)[!names(covs)%in% names(covs_pc)])
names(dat)
#Load data and covariates stacks based on correlation
covs <-rast( paste0("02-Outputs/", i,"_covariates.tif"))
covs <-  c(covs, covs_pc)
# Load the processed data for digital soil mapping. This table was prepared in the 'data_preparation_profiles' script
dat <- read.csv(paste0("02-Outputs/",i,"_dat_train.csv"))
names(dat)
# extract values from covariates to the soil points
projcrs <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
dat <- st_as_sf(dat,
coords = c("X", "Y"),
crs = projcrs)
# Extract values from covariates to the soil points
dat <- cbind(dat[,i],extract(x = covs, y =vect(dat), sp = TRUE))
# Remove NA values
dat<-as.data.frame(dat)
dat <- dat[complete.cases(dat),]
#Load data and covariates stacks based on correlation
covs <-rast( paste0("02-Outputs/", i,"_covariates.tif"))
covs <-  c(covs, covs_pc)
# Load the processed data for digital soil mapping. This table was prepared in the 'data_preparation_profiles' script
dat <- read.csv(paste0("02-Outputs/",i,"_dat_train.csv"))
names(dat)
# extract values from covariates to the soil points
projcrs <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
dat <- st_as_sf(dat,
coords = c("X", "Y"),
crs = projcrs)
# Extract values from covariates to the soil points
pv <- extract(x = covs, y = vect(dat),xy=F)
dat <- cbind(dat,pv)
summary(dat)
# Remove NA values
dat <-as.data.frame(dat)
dat[, 'geometry'] <-NULL
dat <- dat[complete.cases(dat),]
# Defined formulas and QRF parameters
fitControl <- trainControl(method = "repeatedcv",
number = 10,         ## 10 -fold CV
repeats = 3,        ## repeated 3 times
verboseIter = TRUE,
returnData = TRUE)
fm = as.formula(paste(i," ~", paste0(names(covs)[!names(covs)%in% names(covs_pc)],
collapse = "+")))
fm_pc = as.formula(paste(i," ~", paste0(names(covs_pc),
collapse = "+")))
tuneGrid <-  expand.grid(mtry = c(100, 200, 500))
#Calibrate the model using multiple cores
cl <- makeCluster(detectCores()-2)
registerDoParallel(cl)
dat <- as.data.frame(dat)
#Correlation covariates
model <- caret::train(fm,
data = dat[, c(i,names(covs)[!names(covs)%in% names(covs_pc)])],
method = "qrf",
trControl = fitControl,
verbose = TRUE,
tuneGrid = tuneGrid,
keep.inbag = T)
print(model)
print(paste("qrf model = ", i))
#Extract predictor importances as relative values (%)
model$importance <-
data.frame(var=rownames(importance(model$finalModel)),
importance(model$finalModel)/sum(importance(model$finalModel))*100) %>%
arrange(desc(IncNodePurity))
# print(model)
saveRDS(model, file = paste0("02-Outputs/model_", soilatt[i], ".rds"))
#PC covariates
model_pc <- caret::train(fm_pc,
data = dat[, c(i, names(covs_pc))],
method = "qrf",
trControl = fitControl,
verbose = TRUE,
tuneGrid = tuneGrid,
keep.inbag = T)
print(model_pc)
print(paste("qrf model = ", soilatt[i]))
#Extract predictor importances as relative values (%)
model_pc$importance <-
data.frame(var=rownames(importance(model_pc$finalModel)),
importance(model_pc$finalModel)/sum(importance(model_pc$finalModel))*100) %>%
arrange(desc(IncNodePurity))
# print(model)
saveRDS(model_pc, file = paste0("02-Outputs/model_PC_", i, ".rds"))
stopCluster(cl)
gc()
#Quality Assuarance (RMSE,Rsquared,MAE)
model_pc <-readRDS(file = paste0("02-Outputs/model_PC_", i, ".rds"))
model <-readRDS(file = paste0("02-Outputs/model_", i, ".rds"))
#Select final model (PC vs correlation) based on RMSE,Rsquared,MAE
mod_sel <- data.frame(model=0,model_pc=0)
if(max(model$results$Rsquared)>max(model_pc$results$Rsquared)){
mod_sel$model <- 1
mod_sel$model_pc <- 0
}else{
mod_sel$model <- 0
mod_sel$model_pc <- 1 }
if(max(model$results$RMSE)<max(model_pc$results$RMSE)){
mod_sel$model <-mod_sel$model +1
}else{
mod_sel$model_pc <-mod_sel$model_pc +1
}
if(max(model$results$MAE)<max(model_pc$results$MAE)){
mod_sel$model <-mod_sel$model +1
}else{
mod_sel$model_pc <-mod_sel$model_pc +1
}
if(mod_sel$model > mod_sel$model_pc){
mod_sel <- 'Model based on correlated covaraites'
final_mod <-'model_'
}else{
mod_sel <- 'Model based on PCs'
final_mod <-'model_PC_'
}
print(paste('Final Model to select:',mod_sel ))
model$results
model_pc$results
# Predict and map selected soil attributes with the best model ----
# Make tiles to run model in parallel
r <-rast(covs[[1]])
t <- rast(nrows = 5, ncols = 5, extent = ext(r), crs = crs(r))
j=1
t <- rast(tile[j])
tile <- makeTiles(r, t,overwrite=TRUE,filename="02-Outputs/tiles/tiles.tif")
t <- rast(tile[j])
covst <- crop(covs, t)
# plot(r)#
pred_mean <- predict(covst, model = model_pc, na.rm=TRUE,
cpkgs="randomForest", what="mean",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_", j, ".tif"),
overwrite = TRUE)
pred_sd <- predict(r, model = model$finalModel, na.rm=TRUE,
cpkgs="randomForest", what="sd",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_SD_", j, ".tif"),
overwrite = TRUE)
pred_sd <- predict(covst, model = model$finalModel, na.rm=TRUE,
cpkgs="randomForest", what="sd",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_SD_", j, ".tif"),
overwrite = TRUE)
# plot(r)#
pred_mean <- predict(covst, model = model, na.rm=TRUE,
cpkgs="randomForest", what="mean",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_", j, ".tif"),
overwrite = TRUE)
pred_sd <- predict(covst, model = model, na.rm=TRUE,
cpkgs="randomForest", what="sd",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_SD_", j, ".tif"),
overwrite = TRUE)
#Quality Assuarance (RMSE,Rsquared,MAE)
model_pc <-readRDS(file = paste0("02-Outputs/model_PC_", i, ".rds"))
model <-readRDS(file = paste0("02-Outputs/model_", i, ".rds"))
model
# Predict and map selected soil attributes with the best model ----
# Make tiles to run model in parallel
r <-rast(covs[[1]])
t <- rast(nrows = 5, ncols = 5, extent = ext(r), crs = crs(r))
t <- rast(tile[j])
covst <- crop(covs, t)
# plot(r)#
pred_mean <- predict(covst, model = model, na.rm=TRUE,
cpkgs="randomForest", what="mean",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_", j, ".tif"),
overwrite = TRUE)
names(covs)
fm
model$trainingData
#Empty environment and cache ----
rm(list = ls());
gc()
# Working directory
# wd <- 'C:/Users/luottoi/Documents/GitHub/Digital-Soil-Mapping'
wd <- 'C:/Users/hp/Documents/GitHub/Digital-Soil-Mapping'
# Folder to store global layers from Zenodo
output_dir <-'C:/Users/hp/Documents/FAO/data/OpenLandMap/'
# Area of interest
AOI <- '01-Data/MKD.shp'
#Start and End time
start_T <- "2017-01-01"
end_T <- "2017-12-31"
# GEE Resolution (CRS defined based on the first TerraClimate layer WGS84 )
res = 1000
# OpenLandMap Resolution 2km 1km, 250 m or 500 m
resOLM <- '1km'
# Load libraries ----
library(data.table)
library(terra)
library(sf)
library(rgee)
library(zen4R)
library(reticulate)
setwd(wd)
# Country shapefile
AOI <- read_sf(AOI)
# Mean annual temperature (daytime) ----
ee_Initialize()
region <- sf_as_ee(AOI)
region = region$geometry()
image1 <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE") %>%
ee$ImageCollection$filterDate(start_T, end_T) %>%
ee$ImageCollection$select("tmmx")%>%
ee$ImageCollection$filterBounds(region)%>%
ee$ImageCollection$toBands()
# from imagecollection to image
image2 <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE") %>%
ee$ImageCollection$filterDate(start_T, end_T) %>%
ee$ImageCollection$select("tmmn")%>%
ee$ImageCollection$toBands()
image1 <- image1$multiply(0.1)
# Folder to store global layers from Zenodo
#output_dir <-'C:/Users/hp/Documents/FAO/data/OpenLandMap/'
output_dir <-'C:/Users/luottoi/Documents/data/OpenLandMap/'
#######################################################
#
#  Process and download covariates
#  from GEE and Zenodo to R
#
#  Export both raw covariates and PCAs
#
# GSP-Secretariat
# Contact: Isabel.Luotto@fao.org
#
#######################################################
#Empty environment and cache ----
rm(list = ls());
gc()
#######################################################
#
#  User defined variables:
# Working directory
# wd <- 'C:/Users/luottoi/Documents/GitHub/Digital-Soil-Mapping'
wd <- 'C:/Users/hp/Documents/GitHub/Digital-Soil-Mapping'
# Folder to store global layers from Zenodo
#output_dir <-'C:/Users/hp/Documents/FAO/data/OpenLandMap/'
output_dir <-'C:/Users/luottoi/Documents/data/OpenLandMap/'
# Area of interest
AOI <- '01-Data/MKD.shp'
#Start and End time
start_T <- "2017-01-01"
end_T <- "2017-12-31"
# GEE Resolution (CRS defined based on the first TerraClimate layer WGS84 )
res = 1000
# OpenLandMap Resolution 2km 1km, 250 m or 500 m
resOLM <- '1km'
#
#
#######################################################
# Load libraries ----
library(data.table)
library(terra)
library(sf)
library(rgee)
library(zen4R)
library(reticulate)
# Set working directory ----
setwd(wd)
# Country shapefile
AOI <- read_sf(AOI)
# convert AOI to a box polygon
#AOI <- st_as_sfc(st_bbox(AOI))
#AOI <- st_as_sf(AOI)
#List of covariates to prepare
# Mean annual temperature
# Total annual Precipitation
# Precipitation of wettest month
# Precipitation of driest month
# TAGEE 13 soil attributes (list below)
# MODIS EVI & NDVI
# Daytime temperature SD
# Landsat 8 RED and NIR standard deviation
# OpenLandMap
# soil water content 0-10-30
# Potential FAPAR Monthly
# Multi-Scale Topographic Position Index
# Mean annual temperature (daytime) ----
ee_Initialize()
region <- sf_as_ee(AOI)
region = region$geometry()
image1 <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE") %>%
ee$ImageCollection$filterDate(start_T, end_T) %>%
ee$ImageCollection$select("tmmx")%>%
ee$ImageCollection$filterBounds(region)%>%
ee$ImageCollection$toBands()
# from imagecollection to image
image2 <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE") %>%
ee$ImageCollection$filterDate(start_T, end_T) %>%
ee$ImageCollection$select("tmmn")%>%
ee$ImageCollection$toBands()
image1 <- image1$multiply(0.1)
image2 <- image2$multiply(0.1)
diff <- image1$add(image2)
avT = diff$divide(2)
avT = avT$reduce(ee$Reducer$mean())
proj = avT$projection()$getInfo()
crs = proj$wkt
# install TAGEE
system("pip install tagee")
# Import
TAGEE <- import("tagee")
image <- ee$Image("MERIT/DEM/v1_0_3") %>%
ee$Image$clip(region)%>%
ee$Image$toDouble()
image = image$resample('bilinear')$reproject(
crs= crs,
scale= res)
DEMAttributes = TAGEE$terrainAnalysis(image,region)
DEMAttributes =   DEMAttributes$unmask(0)
tageer <- ee_as_raster(
image = DEMAttributes,
scale= res,
region = region,
via = "drive"
)
paste0('terrain.A.', 1:lenght(tageer))
paste0('terrain.A.', 1:length(tageer))
nlayers
tageer
paste0('terrain.A.', 1:dim(tageer))
paste0('terrain.A.', 1:length(tageer@layers))
names(tageer) <- paste0('terrain.A.', 1:length(tageer@layers))
plot(tageer)
writeRaster(tageer, '01-Data/covs/Terrain_attributes.tif', overwrite=T)
#######################################################
#
#  Select covariates
#  based on PCA and Correlation
#
# GSP-Secretariat
# Contact: Isabel.Luotto@fao.org
#
#######################################################
#Empty environment and cache
rm(list = ls());
gc()
#######################################################
#
#  User defined variables: ----
# Working directory
wd <- 'C:/Users/luottoi/Documents/GitHub/Digital-Soil-Mapping'
#wd <- 'C:/Users/hp/Documents/GitHub/Digital-Soil-Mapping'
#List of soil attributes prepared in script #2
soilatt <- c('OCS','clay', 'pH')
#
#
#######################################################
# Set working directory
setwd(wd)
# load packages
library(sf)
library(terra)
library(data.table)
library(reshape)
# Selection based on correlation ----
# list all .tif files the 'covs' folder and load them in a raster stack.
# all rasters should have same extent, resoultion and coordinate system
files <- list.files(path = "01-Data/covs", pattern = "tif*$", full.names = TRUE)
covs <- rast(files)
# Explore the data
names(covs)
for (i in unique(soilatt)){
# Load the processed data for digital soil mapping.
# This table was prepared in the 'data_preparation_profiles' script
dat <- fread(paste0("02-Outputs/",i,"_dat_train.csv"))
#Use coordinates to turn point data into a vector with coordinates
# WGS84
projcrs <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
dat <- st_as_sf(dat,
coords = c("X", "Y"),
crs = projcrs)
# Extract values from covariates to the soil points
pv <- extract(x = covs, y = vect(dat),xy=F)
dat <- cbind(dat,pv)
summary(dat)
# Remove NA values
dat <-as.data.frame(dat)
dat[, 'geometry'] <-NULL
dat <- dat[complete.cases(dat),]
# Test correlation between each covariate and the soil attribute
names(dat)
test_covs <- cor(x = as.matrix(dat[,i]),
y = as.matrix(dat[,names(covs)]))
test_covs
# Select only the covariates that have correlation higher than 0.3
x <- subset(melt(test_covs), value != 1 | complete.cases(test_covs))
x <- x[with(x, order(-abs(x$value))),]
(x <- subset(x,abs(x$value)>0.20))
selection <- as.character(x$X2)
# Leave only selected covariates in the 'covs' raster stack
covs <- covs[[selection]]
names(covs)
writeRaster(covs, file = paste0("02-Outputs/", i,"_covariates.tif"))
print(i)
}
#Add categorical layers
# # Import land cover layer
# landcover <- raster('01-Data/land cover/LandCover.tif')
# landcover <- projectRaster(landcover, covs$EVI,)
#
# # Import and explore the soil map (vector polygon data)
# soilmap<-shapefile("01-Data/Soil map/SoilTypes.shp")
# plot(soilmap)
# summary(soilmap)
#
# # We will use 'Symbol' attribute as an indication of soil type. It has to be 'factor' type.
# soilmap@data$Symbol <- as.factor(soilmap@data$Symbol)
#
# # Rasterize the soil map using one of the 'covs' as a template and 'Symbol' as value field
# soilmap.r <- rasterize(x = soilmap, fun='first', y = covs$Terrain_attributes.1, field = "Symbol")
#
# # Save the rasterized map
# writeRaster(soilmap.r, '02-Outputs/Soil_map.tif', overwrite=TRUE)
#
#
# for (i in unique(soilatt)){
#
#  load(file = paste0("02-Outputs/", i,"_covariates.RData"))
#
#   # stack it with the other rasters
#   covs <- stack(covs, landcover)
#
#   # Now we can stack it with the other rasters
#   covs <- stack(covs, soilmap.r)
#   names(covs)
#   # correct the name
#   names(covs)[names(covs)=='layer'] <- "soilmap"
#
#   # Mask the covariates with the country mask
#   mask <- shapefile('01-Data/MKD.shp')
#   covs <- mask(x = covs, mask = mask)
#
#   save(covs, file = paste0("02-Outputs/", i,"_covariates.RData"))
#
# }
#Empty environment and cache
rm(list = ls());
gc()
# Working directory
wd <- 'C:/Users/luottoi/Documents/GitHub/Digital-Soil-Mapping'
#wd <- 'C:/Users/hp/Documents/GitHub/Digital-Soil-Mapping'
#List of soil attributes prepared in script #2
soilatt <- c('OCS','clay', 'pH')
AOI <- '01-Data/MKD.shp'
#
#
#######################################################
# Set working directory
setwd(wd)
############################### Prapare the final table for modelling (regression matrix)
library(tidyverse)
library(data.table)
library(caret)
library(quantregForest)
library(terra)
library(sf)
library(doParallel)
# Load PC covariates (the same for all soil attributes)
covs_pc <- rast('02-Outputs/PCA_covariates.tif')
i='OCS'
#Load data and covariates stacks based on correlation
covs <-rast( paste0("02-Outputs/", i,"_covariates.tif"))
covs <-  c(covs, covs_pc)
# Load the processed data for digital soil mapping. This table was prepared in the 'data_preparation_profiles' script
dat <- read.csv(paste0("02-Outputs/",i,"_dat_train.csv"))
names(dat)
# extract values from covariates to the soil points
projcrs <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
dat <- st_as_sf(dat,
coords = c("X", "Y"),
crs = projcrs)
# Extract values from covariates to the soil points
pv <- extract(x = covs, y = vect(dat),xy=F)
dat <- cbind(dat,pv)
summary(dat)
# Remove NA values
dat <-as.data.frame(dat)
dat[, 'geometry'] <-NULL
dat <- dat[complete.cases(dat),]
# Defined formulas and QRF parameters
fitControl <- trainControl(method = "repeatedcv",
number = 10,         ## 10 -fold CV
repeats = 3,        ## repeated 3 times
verboseIter = TRUE,
returnData = TRUE)
fm = as.formula(paste(i," ~", paste0(names(covs)[!names(covs)%in% names(covs_pc)],
collapse = "+")))
fm
#Quality Assuarance (RMSE,Rsquared,MAE)
model_pc <-readRDS(file = paste0("02-Outputs/model_PC_", i, ".rds"))
model <-readRDS(file = paste0("02-Outputs/model_", i, ".rds"))
# Predict and map selected soil attributes with the best model ----
# Make tiles to run model in parallel
r <-rast(covs[[1]])
t <- rast(nrows = 5, ncols = 5, extent = ext(r), crs = crs(r))
tile <- makeTiles(r, t,overwrite=TRUE,filename="02-Outputs/tiles/tiles.tif")
gc()
t <- rast(tile[j])
covst <- crop(covs, t)
j=1
gc()
t <- rast(tile[j])
covst <- crop(covs, t)
# plot(r)#
pred_mean <- predict(covst, model = model, na.rm=TRUE,
cpkgs="randomForest", what="mean",
filename = paste0("02-Outputs/Final Maps/tiles/", i,"_tile_", j, ".tif"),
overwrite = TRUE)
names(model$trainingData)
names(covst)
